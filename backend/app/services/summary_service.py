"""Service for generating summaries and closing statements"""

from  llm.gemini_client import model
import logging
import json
import re

logger = logging.getLogger(__name__)


def transliterate_to_devanagari(name: str) -> str:
    """Convert English name to Devanagari script using LLM"""
    if not name:
        return name

    prompt = f"""Convert the following English name to Devanagari (Hindi) script.
    Only return the converted name, nothing else.
    
    Name: {name}
    
    Devanagari:"""

    try:
        logger.info("=" * 80)
        logger.info("ЁЯдЦ LLM CALL (transliterate_to_devanagari) - Input:")
        logger.info(f"Name: {name}")
        logger.info("-" * 80)

        response = model.generate_content(prompt)

        if response and response.text:
            result = response.text.strip()
            # Strip special tokens that GPT-OSS models sometimes include
            result = re.sub(r'<\|[^|]+\|>', '', result)  # Remove <|token|> patterns
            result = re.sub(r'<return>', '', result, flags=re.IGNORECASE)
            result = result.strip()
            logger.info("ЁЯУе LLM CALL (transliterate_to_devanagari) - Raw Response:")
            logger.info(response.text)
            logger.info("-" * 80)
            logger.info(f"тЬЕ LLM CALL (transliterate_to_devanagari) - Result: {result}")
            logger.info("=" * 80)
            return result

        logger.warning(
            "тЪая╕П LLM CALL (transliterate_to_devanagari) - Empty response, returning original name"
        )
        logger.info("=" * 80)
        return name
    except Exception as e:
        logger.error(
            f"тЭМ LLM CALL (transliterate_to_devanagari) - Error: {e}", exc_info=True
        )
        logger.info("=" * 80)
        return name


def generate_human_summary(session: dict) -> str:
    """Generate a human-readable summary from session data using LLM"""
    # Filter out internal fields
    summary_data = {
        k: v
        for k, v in session.items()
        if v is not None
        and k
        not in [
            "session_id",
            "current_question",
            "retry_count",
            "call_should_end",
            "phase",
            "generated_summary",
            "summary_confirmed",
            "acknowledgment_text",
            "customer_name_english",
            "identify_confirmation",
        ]
    }

    # FIX 3: Improved prompt with clear structure for payee, executive, reason, date
    prompt = f"""
        рдЖрдк рдПрдХ рдХрд╕реНрдЯрдорд░ рд╕рд░реНрд╡рд┐рд╕ рдкреНрд░рддрд┐рдирд┐рдзрд┐ рд╣реИрдВ рдФрд░ рдЧреНрд░рд╛рд╣рдХ рд╕реЗ рдлрд╝реЛрди рдкрд░ рд╕реНрд╡рд╛рднрд╛рд╡рд┐рдХ рдмрд╛рддрдЪреАрдд рдХрд░ рд░рд╣реЗ рд╣реИрдВред
        рдиреАрдЪреЗ рджрд┐рдП рдЧрдП рд╡рд╛рд░реНрддрд╛рд▓рд╛рдк рдбреЗрдЯрд╛ рдХреЗ рдЖрдзрд╛рд░ рдкрд░ рд╣рд┐рдВрджреА (рдХреЗрд╡рд▓ рджреЗрд╡рдирд╛рдЧрд░реА рд▓рд┐рдкрд┐ рдореЗрдВ) рдПрдХ рд╕рд░рд▓, рдмреЛрд▓рдЪрд╛рд▓ рдХреА рдкреБрд╖реНрдЯрд┐-рд╡рд╛рд▓реА рдкрдВрдХреНрддрд┐ рддреИрдпрд╛рд░ рдХрд░реЗрдВред

        {json.dumps(summary_data, indent=2, ensure_ascii=False)}

        рдорд╣рддреНрд╡рдкреВрд░реНрдг рдирд┐рд░реНрджреЗрд╢:
        1. рдЙрддреНрддрд░ рдРрд╕рд╛ рд╣реЛ рдЬреИрд╕реЗ рдЖрдк рдХреЙрд▓ рдкрд░ рдЧреНрд░рд╛рд╣рдХ рд╕реЗ рд╡рд┐рд╡рд░рдг рдХреА рдкреБрд╖реНрдЯрд┐ рдХрд░ рд░рд╣реЗ рд╣реЛрдВред
        2. рднрд╛рд╖рд╛ рд╕реНрд╡рд╛рднрд╛рд╡рд┐рдХ рд╣рд┐рдВрджреА / рдЖрдо рдмреЛрд▓рдЪрд╛рд▓ рд╡рд╛рд▓реА рд╣реЛ, рд▓реЗрдХрд┐рди рд░реЛрдорди рд▓рд┐рдкрд┐ рдХрд╛ рдкреНрд░рдпреЛрдЧ рдмрд┐рд▓реНрдХреБрд▓ рди рдХрд░реЗрдВред
        3. рдкреВрд░рд╛ рдЙрддреНрддрд░ рдХреЗрд╡рд▓ рджреЗрд╡рдирд╛рдЧрд░реА рд▓рд┐рдкрд┐ рдореЗрдВ рд╣реЛ; рдХреЛрдИ рднреА рдЕрдВрдЧреНрд░реЗрдЬрд╝реА рдпрд╛ рд░реЛрдорди рд╢рдмреНрдж рди рд╣реЛрдВред
        4. рднреБрдЧрддрд╛рди рд╕реЗ рдЬреБрдбрд╝реА рдЬрд╛рдирдХрд╛рд░реА рд╣рдореЗрд╢рд╛ рдЗрд╕реА рдХреНрд░рдо рдореЗрдВ рд░рдЦреЗрдВ:
        (рдХ) рдХрд┐рд╕рдиреЗ рднреБрдЧрддрд╛рди рдХрд┐рдпрд╛ (рдпрджрд┐ рдЧреНрд░рд╛рд╣рдХ рдиреЗ рд╕реНрд╡рдпрдВ рдХрд┐рдпрд╛ рд╣реЛ рддреЛ рд╡рд╣реА рджрд░реНрд╢рд╛рдПрдБ)
        (рдЦ) рд░рд╛рд╢рд┐
        (рдЧ) рднреБрдЧрддрд╛рди рдХрд╛ рдХрд╛рд░рдг (рдЬреИрд╕реЗ рдИрдПрдордЖрдИ, рд╕реЗрдЯрд▓рдореЗрдВрдЯ, рдлреЛрд░рдХреНрд▓реЛрдЬрд╝рд░ рдЖрджрд┐)
        (рдШ) рднреБрдЧрддрд╛рди рдХреА рддрд╛рд░реАрдЦ
        (рдЩ) рднреБрдЧрддрд╛рди рдХрд╛ рдорд╛рдзреНрдпрдо (рдСрдирд▓рд╛рдЗрди, рдирдХрдж, рд╢рд╛рдЦрд╛, рдПрдирдПрд╕реАрдПрдЪ рдЖрджрд┐ тАФ рджреЗрд╡рдирд╛рдЧрд░реА рдореЗрдВ)
        (рдЪ) рдХрд┐рд╕реЗ рднреБрдЧрддрд╛рди рдХрд┐рдпрд╛ рдЧрдпрд╛ (рдпрджрд┐ рдлрд╝реАрд▓реНрдб рдПрдЧреНрдЬрд╝реАрдХреНрдпреВрдЯрд┐рд╡ рдХрд╛ рдирд╛рдо рдЙрдкрд▓рдмреНрдз рд╣реЛ рддреЛ)

        рд╡рд╛рдХреНрдп рд╕рдВрд░рдЪрдирд╛ рдХреЗ рдЙрджрд╛рд╣рд░рдг:
        - рдпрджрд┐ рдЧреНрд░рд╛рд╣рдХ рдиреЗ рд╕реНрд╡рдпрдВ рднреБрдЧрддрд╛рди рдХрд┐рдпрд╛ рд╣реЛ:
        "рдЖрдкрдиреЗ [рд░рд╛рд╢рд┐] рд░реБрдкрдпреЗ рдХрд╛ рднреБрдЧрддрд╛рди [рдХрд╛рд░рдг] рдХреЗ рд▓рд┐рдП [рддрд╛рд░реАрдЦ] рдХреЛ рдХрд┐рдпрд╛ рдерд╛ рдФрд░ рдпрд╣ [рднреБрдЧрддрд╛рди рдорд╛рдзреНрдпрдо] рд╕реЗ рдХрд┐рдпрд╛ рдЧрдпрд╛ рдерд╛ред"

        - рдпрджрд┐ рдХрд┐рд╕реА рдЕрдиреНрдп рд╡реНрдпрдХреНрддрд┐ рдиреЗ рднреБрдЧрддрд╛рди рдХрд┐рдпрд╛ рд╣реЛ:
        "[рднреБрдЧрддрд╛рдирдХрд░реНрддрд╛] рдиреЗ [рд░рд╛рд╢рд┐] рд░реБрдкрдпреЗ рдХрд╛ рднреБрдЧрддрд╛рди [рдХрд╛рд░рдг] рдХреЗ рд▓рд┐рдП [рддрд╛рд░реАрдЦ] рдХреЛ рдХрд┐рдпрд╛ рдерд╛ рдФрд░ рдпрд╣ [рднреБрдЧрддрд╛рди рдорд╛рдзреНрдпрдо] рд╕реЗ рдХрд┐рдпрд╛ рдЧрдпрд╛ рдерд╛ред"

        - рдпрджрд┐ рдлрд╝реАрд▓реНрдб рдПрдЧреНрдЬрд╝реАрдХреНрдпреВрдЯрд┐рд╡ рдХреЛ рднреБрдЧрддрд╛рди рдХрд┐рдпрд╛ рдЧрдпрд╛ рд╣реЛ:
        "рдЖрдкрдиреЗ [рд░рд╛рд╢рд┐] рд░реБрдкрдпреЗ [рдПрдХреНрдЬрд╝реАрдХреНрдпреВрдЯрд┐рд╡ рдХрд╛ рдирд╛рдо] рдХреЛ [рдХрд╛рд░рдг] рдХреЗ рд▓рд┐рдП [рддрд╛рд░реАрдЦ] рдХреЛ рджрд┐рдП рдереЗ рдФрд░ рдпрд╣ [рднреБрдЧрддрд╛рди рдорд╛рдзреНрдпрдо] рд╕реЗ рдХрд┐рдпрд╛ рдЧрдпрд╛ рдерд╛ред"

        5. рд╡рд┐рд╡рд░рдг рдмрддрд╛рдиреЗ рдХреЗ рдмрд╛рдж рдЕрдВрдд рдореЗрдВ рдпрд╣ рдкреНрд░рд╢реНрди рдЕрд╡рд╢реНрдп рдкреВрдЫреЗрдВ:
        "рдХреНрдпрд╛ рдпрд╣ рдЬрд╛рдирдХрд╛рд░реА рд╕рд╣реА рд╣реИ?"

        6. рдЕрднрд┐рд╡рд╛рджрди, рдмреБрд▓реЗрдЯ рдкреЙрдЗрдВрдЯ, рд╢реАрд░реНрд╖рдХ рдпрд╛ тАЬрд╕рд╛рд░рд╛рдВрд╢тАЭ рдЬреИрд╕реЗ рд╢рдмреНрдж рди рдЬреЛрдбрд╝реЗрдВред
        7. рд╡рд┐рд░рд╛рдо-рдЪрд┐рд╣реНрдиреЛрдВ рдХрд╛ рд╕рд╣реА рдкреНрд░рдпреЛрдЧ рдХрд░реЗрдВтАФрдЕрд▓реНрдкрд╡рд┐рд░рд╛рдо, рдкреВрд░реНрдгрд╡рд┐рд░рд╛рдо рдФрд░ рдкреНрд░рд╢реНрдирд╡рд╛рдЪрдХ рдЪрд┐рдиреНрд╣ред

        рдЙрджрд╛рд╣рд░рдг рдЖрдЙрдЯрдкреБрдЯ:
        "рдЖрдкрдиреЗ 5000 рд░реБрдкрдпреЗ рдХрд╛ рднреБрдЧрддрд╛рди рдЕрдкрдиреА рдИрдПрдордЖрдИ рдХреЗ рд▓рд┐рдП 15 рджрд┐рд╕рдВрдмрд░ рдХреЛ рдХрд┐рдпрд╛ рдерд╛ рдФрд░ рдпрд╣ рдСрдирд▓рд╛рдЗрди рдорд╛рдзреНрдпрдо рд╕реЗ рдХрд┐рдпрд╛ рдЧрдпрд╛ рдерд╛ред рдХреНрдпрд╛ рдпрд╣ рдЬрд╛рдирдХрд╛рд░реА рд╕рд╣реА рд╣реИ?"

        рдЕрдм рдЙрдкрд░реЛрдХреНрдд рдирд┐рд░реНрджреЗрд╢реЛрдВ рдХреЗ рдЕрдиреБрд╕рд╛рд░ рдЙрддреНрддрд░ рддреИрдпрд╛рд░ рдХрд░реЗрдВред
    """

    try:
        logger.info("=" * 80)
        logger.info("ЁЯдЦ LLM CALL (generate_human_summary) - Input Session Data:")
        logger.info("-" * 80)
        logger.info(json.dumps(summary_data, indent=2, ensure_ascii=False))
        logger.info("-" * 80)

        response = model.generate_content(prompt)

        if response and response.text:
            result = response.text.strip()
            # Strip special tokens that GPT-OSS models sometimes include
            result = re.sub(r'<\|[^|]+\|>', '', result)  # Remove <|token|> patterns
            result = re.sub(r'<return>', '', result, flags=re.IGNORECASE)
            result = result.strip()
            logger.info("ЁЯУе LLM CALL (generate_human_summary) - Raw Response:")
            logger.info(response.text)
            logger.info("-" * 80)
            logger.info(f"тЬЕ LLM CALL (generate_human_summary) - Generated Summary:")
            logger.info(result)
            logger.info("=" * 80)
            return result
        else:
            logger.warning(
                "тЪая╕П LLM CALL (generate_human_summary) - Empty response, using fallback summary"
            )
            logger.info("=" * 80)
            # Fallback to basic summary if LLM fails
            return generate_fallback_summary(summary_data)
    except Exception as e:
        logger.error(
            f"тЭМ LLM CALL (generate_human_summary) - Error: {e}", exc_info=True
        )
        logger.info("=" * 80)
        return generate_fallback_summary(summary_data)


def generate_fallback_summary(data: dict) -> str:
    """Generate a basic conversational summary if LLM fails"""
    summary_parts = []

    # WHO paid
    payee = data.get("payee", "self")
    payee_text = "рдЖрдкрдиреЗ" if payee == "self" else f"{data.get('payee_name', 'рдХрд┐рд╕реА рдиреЗ')}"

    # AMOUNT
    amount = data.get("amount", "")

    # WHY (reason)
    reason = data.get("reason", "")
    reason_map = {
        "emi": "рдИрдПрдордЖрдИ",
        "emi_charges": "рдИрдПрдордЖрдИ рдЪрд╛рд░реНрдЬреЗрдЬ",
        "settlement": "рд╕реЗрдЯрд▓рдореЗрдВрдЯ",
        "foreclosure": "рдлреЛрд░рдХреНрд▓реЛрдЬрд░",
        "charges": "рдЪрд╛рд░реНрдЬреЗрдЬ",
        "loan_cancellation": "рд▓реЛрди рдХреИрдВрд╕рд┐рд▓реЗрд╢рди",
        "advance_emi": "рдПрдбрд╡рд╛рдВрд╕ рдИрдПрдордЖрдИ",
    }
    reason_text = reason_map.get(reason, reason) if reason else "рднреБрдЧрддрд╛рди"

    # WHEN (date)
    pay_date = data.get("pay_date", "")

    # HOW (payment mode)
    mode = data.get("mode_of_payment", "")
    mode_map = {
        "online": "рдСрдирд▓рд╛рдЗрди",
        "online_lan": "рдСрдирд▓рд╛рдЗрди",
        "online_field_executive": "рдСрдирд▓рд╛рдЗрди рдлреАрд▓реНрдб рдПрдЧреНрдЬреАрдХреНрдпреВрдЯрд┐рд╡",
        "cash": "рдирдЧрдж",
        "branch": "рдмреНрд░рд╛рдВрдЪ",
        "outlet": "рдЖрдЙрдЯрд▓реЗрдЯ",
        "nach": "рдСрдЯреЛ рдбреЗрдмрд┐рдЯ (NACH)",
    }
    mode_text = mode_map.get(mode, mode) if mode else ""

    # TO WHOM (executive)
    executive = data.get("field_executive_name", "")

    # Build the summary
    if executive:
        # If executive is mentioned
        summary = f"{payee_text} тВ╣{amount} рд░реБрдкрдпреЗ {executive} рдХреЛ {reason_text} рдХреЗ рд▓рд┐рдП"
        if pay_date:
            summary += f" {pay_date} рдХреЛ"
        summary += " рджрд┐рдП рдереЗ"
        if mode_text:
            summary += f" рдФрд░ рдпрд╣ {mode_text} рд╕реЗ рдХрд┐рдпрд╛ рдерд╛"
    else:
        # No executive
        summary = f"{payee_text} тВ╣{amount} рд░реБрдкрдпреЗ рдХрд╛ рднреБрдЧрддрд╛рди {reason_text} рдХреЗ рд▓рд┐рдП"
        if pay_date:
            summary += f" {pay_date} рдХреЛ"
        summary += " рдХрд┐рдпрд╛ рдерд╛"
        if mode_text:
            summary += f" рдФрд░ рдпрд╣ {mode_text} рдорд╛рдзреНрдпрдо рд╕реЗ рдХрд┐рдпрд╛ рд╣реИ"

    summary += "ред рдХреНрдпрд╛ рдпрд╣ рдЬрд╛рдирдХрд╛рд░реА рд╕рд╣реА рд╣реИ?"

    return summary


def is_survey_completed(session: dict) -> bool:
    """Check if survey is completed without modifying the session"""
    # Lazy import to avoid circular dependency
    from  flow.flow_manager import get_next_question_index
    from  flow.question_order import QUESTIONS

    next_idx = get_next_question_index(session)
    return next_idx >= len(QUESTIONS) or session.get("call_should_end", False)


def detect_confirmation(user_input: str) -> str:
    """Use LLM to detect if user confirmed or denied the summary
    Returns: 'YES', 'NO', or 'UNCLEAR'
    """
    prompt = f"""Analyze the following user response to determine if they are confirming or denying.
    The user was asked: "рдХреНрдпрд╛ рдпрд╣ рдЬрд╛рдирдХрд╛рд░реА рд╕рд╣реА рд╣реИ?" (Is this information correct?)
    
    User response: "{user_input}"
    
    Return ONLY one of these three options:
    - YES (if user confirms, agrees, says correct, sahi hai, theek hai, haan, etc.)
    - NO (if user denies, disagrees, says wrong, galat, nahi, change karna hai, etc.)
    - UNCLEAR (if the response is ambiguous or unrelated)
    
    Response:"""

    try:
        logger.info("=" * 80)
        logger.info("ЁЯдЦ LLM CALL (detect_confirmation) - Input:")
        logger.info(f"User response: {user_input}")
        logger.info("-" * 80)

        response = model.generate_content(prompt)

        if response and response.text:
            result = response.text.strip().upper()
            logger.info("ЁЯУе LLM CALL (detect_confirmation) - Raw Response:")
            logger.info(response.text)
            logger.info("-" * 80)

            if "YES" in result:
                logger.info("тЬЕ LLM CALL (detect_confirmation) - Result: YES")
                logger.info("=" * 80)
                return "YES"
            elif "NO" in result:
                logger.info("тЬЕ LLM CALL (detect_confirmation) - Result: NO")
                logger.info("=" * 80)
                return "NO"

        logger.warning("тЪая╕П LLM CALL (detect_confirmation) - Result: UNCLEAR")
        logger.info("=" * 80)
        return "UNCLEAR"
    except Exception as e:
        logger.error(f"тЭМ LLM CALL (detect_confirmation) - Error: {e}", exc_info=True)
        logger.info("=" * 80)
        return "UNCLEAR"


def detect_field_to_edit(user_input: str, session: dict) -> dict:
    """Use LLM to detect which field the user wants to edit and the new value
    Returns: {"field": field_name, "value": new_value} or None
    """
    # Map of editable fields with their Hindi descriptions
    field_map = {
        "amount": "рд░рд╛рд╢рд┐/рдЕрдорд╛рдЙрдВрдЯ",
        "pay_date": "рднреБрдЧрддрд╛рди рдХреА рддрд╛рд░реАрдЦ/рдбреЗрдЯ",
        "mode_of_payment": "рднреБрдЧрддрд╛рди рдХрд╛ рдорд╛рдзреНрдпрдо/рдореЛрдб",
        "payee": "рдХрд┐рд╕рдиреЗ рднреБрдЧрддрд╛рди рдХрд┐рдпрд╛",
        "reason": "рднреБрдЧрддрд╛рди рдХрд╛ рдХрд╛рд░рдг",
    }

    prompt = f"""Analyze the user's response to determine which field they want to edit and what the new value should be.
    
    Current session data:
    - Amount (рд░рд╛рд╢рд┐): {session.get('amount')}
    - Payment Date (рддрд╛рд░реАрдЦ): {session.get('pay_date')}
    - Payment Mode (рдорд╛рдзреНрдпрдо): {session.get('mode_of_payment')}
    - Payee (рднреБрдЧрддрд╛рди рдХрд░рддрд╛): {session.get('payee')}
    - Reason (рдХрд╛рд░рдг): {session.get('reason')}
    
    User said: "{user_input}"
    
    Return in this exact format (just the field name and value, nothing else):
    FIELD: <field_name>
    VALUE: <new_value>
    
    Field names must be one of: amount, pay_date, mode_of_payment, payee, reason
    If you cannot determine which field to edit, return:
    FIELD: NONE
    VALUE: NONE
    
    Response:"""

    try:
        logger.info("=" * 80)
        logger.info("ЁЯдЦ LLM CALL (detect_field_to_edit) - Input:")
        logger.info(f"User response: {user_input}")
        logger.info("Current session data:")
        logger.info(
            json.dumps(
                {
                    "amount": session.get("amount"),
                    "pay_date": session.get("pay_date"),
                    "mode_of_payment": session.get("mode_of_payment"),
                    "payee": session.get("payee"),
                    "reason": session.get("reason"),
                },
                indent=2,
                ensure_ascii=False,
            )
        )
        logger.info("-" * 80)

        response = model.generate_content(prompt)

        if response and response.text:
            logger.info("ЁЯУе LLM CALL (detect_field_to_edit) - Raw Response:")
            logger.info(response.text)
            logger.info("-" * 80)

            lines = response.text.strip().split("\n")
            field = None
            value = None
            for line in lines:
                if line.startswith("FIELD:"):
                    field = line.replace("FIELD:", "").strip().lower()
                elif line.startswith("VALUE:"):
                    value = line.replace("VALUE:", "").strip()

            if field and field != "none" and value and value.lower() != "none":
                result = {"field": field, "value": value}
                logger.info(
                    f"тЬЕ LLM CALL (detect_field_to_edit) - Result: {json.dumps(result, indent=2, ensure_ascii=False)}"
                )
                logger.info("=" * 80)
                return result

        logger.warning(
            "тЪая╕П LLM CALL (detect_field_to_edit) - Could not detect field, returning None"
        )
        logger.info("=" * 80)
        return None
    except Exception as e:
        logger.error(f"тЭМ LLM CALL (detect_field_to_edit) - Error: {e}", exc_info=True)
        logger.info("=" * 80)
        return None


def get_edit_prompt() -> str:
    """Get the prompt asking which field to edit"""
    return "рдХреМрди рд╕реА рдЬрд╛рдирдХрд╛рд░реА рдмрджрд▓рдиреА рд╣реИ? рдХреГрдкрдпрд╛ рдмрддрд╛рдЗрдПред"


def get_closing_statement(session: dict) -> str:
    """Generate closing statement based on session data"""
    call_end_reason = session.get("call_end_reason")
    
    if session.get("call_should_end"):
        # Check if it's a wrong number case (loan_taken is NO)
        if session.get("loan_taken") == "NO":
            return "рдзрдиреНрдпрд╡рд╛рдж рдЖрдкрдХреЗ рд╕рдордп рдХреЗ рд▓рд┐рдПред\nрдЖрдкрдХрд╛ рджрд┐рди рд╢реБрдн рд╣реЛ!"
        # Check if alternate number was provided
        elif session.get("user_contact"):
            return (
                "рдзрдиреНрдпрд╡рд╛рдж рдЖрдкрдХреЗ рд╕рдордп рдХреЗ рд▓рд┐рдПред\n"
                "рд╣рдо рдЖрдкрдХреЗ рджреНрд╡рд╛рд░рд╛ рдмрддрд╛рдП рдЧрдП рд╕рдордп рдкрд░ рдЙрдирд╕реЗ рд╕рдВрдкрд░реНрдХ рдХрд░реЗрдВрдЧреЗред\n"
                "рдЖрдкрдХрд╛ рджрд┐рди рд╢реБрдн рд╣реЛ!"
            )
        elif session.get("last_month_emi_payment") == "NO":
            return (
                "рдзрдиреНрдпрд╡рд╛рдж рдЖрдкрдХреЗ рд╕рдордп рдХреЗ рд▓рд┐рдПред\n"
                "рдЖрдкрдХреА рдлреАрдбрдмреИрдХ рд╣рдорд╛рд░реЗ рд▓рд┐рдП рдмрд╣реБрдд рдорд╣рддреНрд╡рдкреВрд░реНрдг рд╣реИред\n"
                "рдЖрдкрдХрд╛ рджрд┐рди рд╢реБрдн рд╣реЛ!"
            )
    else:
        return (
            "рдЖрдкрдХреЗ рдореВрд▓реНрдпрд╡рд╛рди рдлрд╝реАрдбрдмреИрдХ рдФрд░ рд╕рдордп рджреЗрдиреЗ рдХреЗ рд▓рд┐рдП рдзрдиреНрдпрд╡рд╛рджред\n"
            "рдЖрдкрдХрд╛ рджрд┐рди рд╢реБрдн рд╣реЛред"
        )
