"""
Filler Manager - Manages Hindi filler words for reducing perceived latency
Uses similarity search to select appropriate fillers based on transcript and question context
"""
import random
import logging
from typing import Optional, Dict, List
from difflib import SequenceMatcher

logger = logging.getLogger(__name__)

# Hindi filler words/phrases (neutral, 2-3 words and 3+ words)
HINDI_FILLERS = [
    # 2-3 word fillers
    "à¤¨à¥‹à¤Ÿ à¤•à¤° à¤²à¤¿à¤¯à¤¾...",
    "à¤†à¤—à¥‡ à¤¬à¥à¤¤à¥‡ à¤¹à¥ˆà¤‚...",
    "à¤à¤• à¤¸à¥‡à¤•à¤‚à¤¡...",
    "à¤à¤• à¤®à¤¿à¤¨à¤Ÿ...",
    "à¤†à¤—à¥‡ à¤¬à¤¤à¤¾à¤‡à¤...",
    "à¤¹à¤¾à¤, à¤¨à¥‹à¤Ÿ à¤•à¤° à¤²à¤¿à¤¯à¤¾...",
    "à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ...",
    "à¤¸à¥à¤¨ à¤°à¤¹à¤¾ à¤¹à¥ˆ...",
    "à¤§à¥à¤¯à¤¾à¤¨ à¤¦à¥‡ à¤°à¤¹à¤¾ à¤¹à¥ˆ...",
    "à¤œà¤¾à¤°à¥€ à¤°à¤–à¥‡à¤‚...",
    "à¤ à¥€à¤• à¤¹à¥ˆ...",
    "à¤¸à¤®à¤ à¤—à¤¯à¤¾...",
    "à¤œà¥€ à¤¹à¤¾à¤...",
    "à¤¬à¤¿à¤²à¥à¤•à¥à¤² à¤¸à¤¹à¥€...",
    # 3+ word fillers
    "à¤à¤• à¤ªà¤² à¤‡à¤‚à¤¤à¤œà¤¼à¤¾à¤° à¤•à¤°à¥‡à¤‚...",
    "à¤¨à¥‹à¤Ÿ à¤•à¤° à¤²à¤¿à¤¯à¤¾ à¤¹à¥ˆ...",
    "à¤¬à¤¸ à¤•à¥à¤› à¤¹à¥€ à¤¸à¤µà¤¾à¤² à¤”à¤°...",
    "à¤…à¤—à¤²à¤¾ à¤µà¤¿à¤·à¤¯ à¤¹à¥ˆ...",
    "à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤•à¥‡ à¤²à¤¿à¤ à¤¶à¥à¤•à¥à¤°à¤¿à¤¯à¤¾à¥¤",
    "à¤œà¥€, à¤§à¥à¤¯à¤¾à¤¨ à¤¸à¥‡ à¤¸à¥à¤¨ à¤°à¤¹à¤¾ à¤¹à¥ˆ...",
    "à¤¬à¤¿à¤²à¥à¤•à¥à¤², à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ...",
    "à¤ à¥€à¤• à¤¹à¥ˆ, à¤†à¤—à¥‡ à¤¬à¥à¤¤à¥‡ à¤¹à¥ˆà¤‚...",
    "à¤¸à¤®à¤ à¤—à¤¯à¤¾, à¤œà¤¾à¤°à¥€ à¤°à¤–à¥‡à¤‚...",
    "à¤œà¥€ à¤¹à¤¾à¤, à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ...",
    "à¤¬à¤¿à¤²à¥à¤•à¥à¤² à¤¸à¤¹à¥€, à¤¨à¥‹à¤Ÿ à¤•à¤° à¤²à¤¿à¤¯à¤¾...",
    "à¤à¤• à¤¸à¥‡à¤•à¤‚à¤¡, à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ...",
    "à¤ à¥€à¤• à¤¹à¥ˆ, à¤§à¥à¤¯à¤¾à¤¨ à¤¸à¥‡ à¤¸à¥à¤¨ à¤°à¤¹à¤¾ à¤¹à¥ˆ...",
    "à¤¹à¤¾à¤, à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤®à¤¿à¤² à¤—à¤ˆ...",
    "à¤¸à¤®à¤ à¤—à¤¯à¤¾, à¤†à¤—à¥‡ à¤¬à¤¤à¤¾à¤‡à¤...",
    "à¤œà¥€, à¤¸à¤¬ à¤•à¥à¤› à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ...",
    "à¤ à¥€à¤• à¤¹à¥ˆ, à¤…à¤—à¤²à¤¾ à¤¸à¤µà¤¾à¤² à¤¹à¥ˆ...",
    "à¤¹à¤¾à¤, à¤¯à¤¹ à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤®à¤¿à¤² à¤—à¤ˆ...",
    "à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ, à¤œà¤¾à¤°à¥€ à¤°à¤–à¥‡à¤‚...",
    "à¤¬à¤¿à¤²à¥à¤•à¥à¤², à¤¨à¥‹à¤Ÿ à¤•à¤° à¤²à¤¿à¤¯à¤¾ à¤¹à¥ˆ...",
    "à¤ à¥€à¤• à¤¹à¥ˆ, à¤†à¤ª à¤¬à¤¤à¤¾à¤¤à¥‡ à¤°à¤¹à¤¿à¤...",
    "à¤¹à¤¾à¤, à¤¯à¤¹ à¤¸à¤¹à¥€ à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤¹à¥ˆ...",
    "à¤à¤• à¤®à¤¿à¤¨à¤Ÿ, à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ...",
    "à¤ à¥€à¤• à¤¹à¥ˆ, à¤¨à¥‹à¤Ÿ à¤•à¤° à¤²à¤¿à¤¯à¤¾...",
    "à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ, à¤†à¤—à¥‡ à¤¬à¤¤à¤¾à¤‡à¤...",
    "à¤œà¥€, à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤®à¤¿à¤² à¤—à¤ˆ...",
    "à¤¬à¤¿à¤²à¥à¤•à¥à¤², à¤§à¥à¤¯à¤¾à¤¨ à¤¸à¥‡ à¤¸à¥à¤¨ à¤°à¤¹à¤¾ à¤¹à¥ˆ...",
    "à¤¹à¤¾à¤, à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ...",
    "à¤ à¥€à¤• à¤¹à¥ˆ, à¤œà¤¾à¤°à¥€ à¤°à¤–à¥‡à¤‚...",
    "à¤¸à¤®à¤ à¤—à¤¯à¤¾, à¤¨à¥‹à¤Ÿ à¤•à¤° à¤²à¤¿à¤¯à¤¾...",
    "à¤œà¥€ à¤¹à¤¾à¤, à¤¨à¥‹à¤Ÿ à¤•à¤° à¤²à¤¿à¤¯à¤¾...",
    "à¤¬à¤¿à¤²à¥à¤•à¥à¤², à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤®à¤¿à¤² à¤—à¤ˆ...",
    "à¤¹à¤¾à¤, à¤§à¥à¤¯à¤¾à¤¨ à¤¸à¥‡ à¤¸à¥à¤¨ à¤°à¤¹à¤¾ à¤¹à¥ˆ...",
    "à¤ à¥€à¤• à¤¹à¥ˆ, à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ...",
    "à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ, à¤¨à¥‹à¤Ÿ à¤•à¤° à¤²à¤¿à¤¯à¤¾...",
    "à¤œà¥€, à¤†à¤—à¥‡ à¤¬à¤¤à¤¾à¤‡à¤...",
    "à¤¬à¤¿à¤²à¥à¤•à¥à¤², à¤œà¤¾à¤°à¥€ à¤°à¤–à¥‡à¤‚...",
    "à¤¹à¤¾à¤, à¤†à¤—à¥‡ à¤¬à¥à¤¤à¥‡ à¤¹à¥ˆà¤‚...",
    "à¤ à¥€à¤• à¤¹à¥ˆ, à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤®à¤¿à¤² à¤—à¤ˆ...",
]

# Lookup table: Maps question types/contexts to appropriate fillers
# Key: keywords or question patterns, Value: list of preferred fillers
FILLER_LOOKUP_TABLE: Dict[str, List[str]] = {
    # Amount/Number related
    "amount": ["à¤¨à¥‹à¤Ÿ à¤•à¤° à¤²à¤¿à¤¯à¤¾...", "à¤¹à¤¾à¤, à¤¨à¥‹à¤Ÿ à¤•à¤° à¤²à¤¿à¤¯à¤¾...", "à¤¬à¤¿à¤²à¥à¤•à¥à¤² à¤¸à¤¹à¥€, à¤¨à¥‹à¤Ÿ à¤•à¤° à¤²à¤¿à¤¯à¤¾...", "à¤¹à¤¾à¤, à¤¯à¤¹ à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤®à¤¿à¤² à¤—à¤ˆ..."],
    "à¤°à¤¾à¤¶à¤¿": ["à¤¨à¥‹à¤Ÿ à¤•à¤° à¤²à¤¿à¤¯à¤¾...", "à¤¹à¤¾à¤, à¤¨à¥‹à¤Ÿ à¤•à¤° à¤²à¤¿à¤¯à¤¾...", "à¤¬à¤¿à¤²à¥à¤•à¥à¤² à¤¸à¤¹à¥€, à¤¨à¥‹à¤Ÿ à¤•à¤° à¤²à¤¿à¤¯à¤¾..."],
    "à¤°à¥à¤ªà¤¯à¥‡": ["à¤¨à¥‹à¤Ÿ à¤•à¤° à¤²à¤¿à¤¯à¤¾...", "à¤¹à¤¾à¤, à¤¨à¥‹à¤Ÿ à¤•à¤° à¤²à¤¿à¤¯à¤¾...", "à¤¬à¤¿à¤²à¥à¤•à¥à¤² à¤¸à¤¹à¥€, à¤¨à¥‹à¤Ÿ à¤•à¤° à¤²à¤¿à¤¯à¤¾..."],
    
    # Date related
    "date": ["à¤¸à¤®à¤ à¤—à¤¯à¤¾...", "à¤¹à¤¾à¤, à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤®à¤¿à¤² à¤—à¤ˆ...", "à¤ à¥€à¤• à¤¹à¥ˆ, à¤¸à¤®à¤ à¤—à¤¯à¤¾...", "à¤¸à¤®à¤ à¤—à¤¯à¤¾, à¤œà¤¾à¤°à¥€ à¤°à¤–à¥‡à¤‚..."],
    "à¤¤à¤¾à¤°à¥€à¤–": ["à¤¸à¤®à¤ à¤—à¤¯à¤¾...", "à¤¹à¤¾à¤, à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤®à¤¿à¤² à¤—à¤ˆ...", "à¤ à¥€à¤• à¤¹à¥ˆ, à¤¸à¤®à¤ à¤—à¤¯à¤¾..."],
    "à¤¦à¤¿à¤¨à¤¾à¤‚à¤•": ["à¤¸à¤®à¤ à¤—à¤¯à¤¾...", "à¤¹à¤¾à¤, à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤®à¤¿à¤² à¤—à¤ˆ..."],
    "à¤•à¤¬": ["à¤¸à¤®à¤ à¤—à¤¯à¤¾...", "à¤¹à¤¾à¤, à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤®à¤¿à¤² à¤—à¤ˆ...", "à¤ à¥€à¤• à¤¹à¥ˆ, à¤¸à¤®à¤ à¤—à¤¯à¤¾..."],
    "à¤¦à¤¿à¤¸à¤‚à¤¬à¤°": ["à¤¸à¤®à¤ à¤—à¤¯à¤¾...", "à¤¹à¤¾à¤, à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤®à¤¿à¤² à¤—à¤ˆ...", "à¤ à¥€à¤• à¤¹à¥ˆ, à¤¸à¤®à¤ à¤—à¤¯à¤¾..."],
    "à¤®à¤¹à¥€à¤¨à¥‡": ["à¤¸à¤®à¤ à¤—à¤¯à¤¾...", "à¤¹à¤¾à¤, à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤®à¤¿à¤² à¤—à¤ˆ...", "à¤ à¥€à¤• à¤¹à¥ˆ, à¤¸à¤®à¤ à¤—à¤¯à¤¾..."],
    
    # Payment mode related
    "mode": ["à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ...", "à¤œà¥€, à¤§à¥à¤¯à¤¾à¤¨ à¤¸à¥‡ à¤¸à¥à¤¨ à¤°à¤¹à¤¾ à¤¹à¥ˆ...", "à¤¬à¤¿à¤²à¥à¤•à¥à¤², à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ...", "à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ, à¤œà¤¾à¤°à¥€ à¤°à¤–à¥‡à¤‚..."],
    "à¤®à¤¾à¤§à¥à¤¯à¤®": ["à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ...", "à¤œà¥€, à¤§à¥à¤¯à¤¾à¤¨ à¤¸à¥‡ à¤¸à¥à¤¨ à¤°à¤¹à¤¾ à¤¹à¥ˆ...", "à¤¬à¤¿à¤²à¥à¤•à¥à¤², à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ..."],
    "à¤‘à¤¨à¤²à¤¾à¤‡à¤¨": ["à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ...", "à¤œà¥€, à¤§à¥à¤¯à¤¾à¤¨ à¤¸à¥‡ à¤¸à¥à¤¨ à¤°à¤¹à¤¾ à¤¹à¥ˆ...", "à¤¬à¤¿à¤²à¥à¤•à¥à¤², à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ..."],
    "à¤¨à¤•à¤¦": ["à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ...", "à¤œà¥€, à¤§à¥à¤¯à¤¾à¤¨ à¤¸à¥‡ à¤¸à¥à¤¨ à¤°à¤¹à¤¾ à¤¹à¥ˆ...", "à¤¬à¤¿à¤²à¥à¤•à¥à¤², à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ..."],
    "à¤¬à¥à¤°à¤¾à¤‚à¤š": ["à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ...", "à¤œà¥€, à¤§à¥à¤¯à¤¾à¤¨ à¤¸à¥‡ à¤¸à¥à¤¨ à¤°à¤¹à¤¾ à¤¹à¥ˆ...", "à¤¬à¤¿à¤²à¥à¤•à¥à¤², à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ..."],
    "à¤•à¥ˆà¤¸à¥‡": ["à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ...", "à¤œà¥€, à¤§à¥à¤¯à¤¾à¤¨ à¤¸à¥‡ à¤¸à¥à¤¨ à¤°à¤¹à¤¾ à¤¹à¥ˆ...", "à¤¬à¤¿à¤²à¥à¤•à¥à¤², à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ..."],
    # Note: "à¤­à¥à¤—à¤¤à¤¾à¤¨" removed as it's too generic and appears in many contexts
    
    # Payee/Who paid related
    "payee": ["à¤¸à¤®à¤ à¤—à¤¯à¤¾...", "à¤¹à¤¾à¤, à¤¸à¤®à¤ à¤—à¤¯à¤¾...", "à¤ à¥€à¤• à¤¹à¥ˆ, à¤¸à¤®à¤ à¤—à¤¯à¤¾...", "à¤¸à¤®à¤ à¤—à¤¯à¤¾, à¤†à¤—à¥‡ à¤¬à¤¤à¤¾à¤‡à¤..."],
    "à¤•à¤¿à¤¸à¤¨à¥‡": ["à¤¸à¤®à¤ à¤—à¤¯à¤¾...", "à¤¹à¤¾à¤, à¤¸à¤®à¤ à¤—à¤¯à¤¾...", "à¤ à¥€à¤• à¤¹à¥ˆ, à¤¸à¤®à¤ à¤—à¤¯à¤¾..."],
    "à¤•à¥Œà¤¨": ["à¤¸à¤®à¤ à¤—à¤¯à¤¾...", "à¤¹à¤¾à¤, à¤¸à¤®à¤ à¤—à¤¯à¤¾...", "à¤ à¥€à¤• à¤¹à¥ˆ, à¤¸à¤®à¤ à¤—à¤¯à¤¾..."],
    
    # Reason/Purpose related
    "reason": ["à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ...", "à¤œà¥€ à¤¹à¤¾à¤, à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ...", "à¤¬à¤¿à¤²à¥à¤•à¥à¤², à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ...", "à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ, à¤œà¤¾à¤°à¥€ à¤°à¤–à¥‡à¤‚..."],
    "à¤•à¤¾à¤°à¤£": ["à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ...", "à¤œà¥€ à¤¹à¤¾à¤, à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ...", "à¤¬à¤¿à¤²à¥à¤•à¥à¤², à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ..."],
    "à¤ˆà¤à¤®à¤†à¤ˆ": ["à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ...", "à¤œà¥€ à¤¹à¤¾à¤, à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ...", "à¤¬à¤¿à¤²à¥à¤•à¥à¤², à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ..."],
    
    # General acknowledgment
    "general": ["à¤à¤• à¤¸à¥‡à¤•à¤‚à¤¡...", "à¤à¤• à¤®à¤¿à¤¨à¤Ÿ...", "à¤à¤• à¤ªà¤² à¤‡à¤‚à¤¤à¤œà¤¼à¤¾à¤° à¤•à¤°à¥‡à¤‚...", "à¤†à¤—à¥‡ à¤¬à¤¤à¤¾à¤‡à¤...", "à¤†à¤—à¥‡ à¤¬à¥à¤¤à¥‡ à¤¹à¥ˆà¤‚..."],
    "acknowledgment": ["à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ...", "à¤œà¥€, à¤§à¥à¤¯à¤¾à¤¨ à¤¸à¥‡ à¤¸à¥à¤¨ à¤°à¤¹à¤¾ à¤¹à¥ˆ...", "à¤¬à¤¿à¤²à¥à¤•à¥à¤², à¤¸à¤®à¤ à¤°à¤¹à¤¾ à¤¹à¥ˆ..."],
    
    # Confirmation/Verification
    "confirmation": ["à¤¬à¤¿à¤²à¥à¤•à¥à¤² à¤¸à¤¹à¥€...", "à¤¹à¤¾à¤, à¤¯à¤¹ à¤¸à¤¹à¥€ à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤¹à¥ˆ...", "à¤¬à¤¿à¤²à¥à¤•à¥à¤², à¤¨à¥‹à¤Ÿ à¤•à¤° à¤²à¤¿à¤¯à¤¾ à¤¹à¥ˆ...", "à¤¹à¤¾à¤, à¤¯à¤¹ à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤®à¤¿à¤² à¤—à¤ˆ..."],
    "à¤¸à¤¹à¥€": ["à¤¬à¤¿à¤²à¥à¤•à¥à¤² à¤¸à¤¹à¥€...", "à¤¹à¤¾à¤, à¤¯à¤¹ à¤¸à¤¹à¥€ à¤œà¤¾à¤¨à¤•à¤¾à¤°à¥€ à¤¹à¥ˆ...", "à¤¬à¤¿à¤²à¥à¤•à¥à¤², à¤¨à¥‹à¤Ÿ à¤•à¤° à¤²à¤¿à¤¯à¤¾ à¤¹à¥ˆ..."],
    
    # Transition/Next question
    "transition": ["à¤†à¤—à¥‡ à¤¬à¥à¤¤à¥‡ à¤¹à¥ˆà¤‚...", "à¤ à¥€à¤• à¤¹à¥ˆ, à¤†à¤—à¥‡ à¤¬à¥à¤¤à¥‡ à¤¹à¥ˆà¤‚...", "à¤…à¤—à¤²à¤¾ à¤µà¤¿à¤·à¤¯ à¤¹à¥ˆ...", "à¤ à¥€à¤• à¤¹à¥ˆ, à¤…à¤—à¤²à¤¾ à¤¸à¤µà¤¾à¤² à¤¹à¥ˆ...", "à¤¬à¤¸ à¤•à¥à¤› à¤¹à¥€ à¤¸à¤µà¤¾à¤² à¤”à¤°..."],
    "next": ["à¤†à¤—à¥‡ à¤¬à¥à¤¤à¥‡ à¤¹à¥ˆà¤‚...", "à¤ à¥€à¤• à¤¹à¥ˆ, à¤†à¤—à¥‡ à¤¬à¥à¤¤à¥‡ à¤¹à¥ˆà¤‚...", "à¤…à¤—à¤²à¤¾ à¤µà¤¿à¤·à¤¯ à¤¹à¥ˆ...", "à¤ à¥€à¤• à¤¹à¥ˆ, à¤…à¤—à¤²à¤¾ à¤¸à¤µà¤¾à¤² à¤¹à¥ˆ..."],
}

# Probability of using filler (85% = 0.85)
FILLER_PROBABILITY = 0.85


def similarity_score(text1: str, text2: str) -> float:
    """
    Calculate similarity score between two texts using SequenceMatcher
    Returns a value between 0.0 and 1.0
    """
    return SequenceMatcher(None, text1.lower(), text2.lower()).ratio()


def find_matching_context(transcript: str, question: Optional[str] = None) -> List[str]:
    """
    Find matching context keywords from transcript and question
    Returns list of matching context keys, prioritized by specificity
    """
    combined_text = (transcript + " " + (question or "")).lower()
    matching_contexts = []
    
    # Priority order: more specific keywords first
    # This ensures specific matches take precedence over generic ones
    priority_keywords = [
        # Most specific - Amount/Number
        "à¤°à¥à¤ªà¤¯à¥‡", "à¤°à¤¾à¤¶à¤¿", "amount",
        # Date specific
        "à¤¤à¤¾à¤°à¥€à¤–", "à¤¦à¤¿à¤¨à¤¾à¤‚à¤•", "date", "à¤•à¤¬", "à¤¦à¤¿à¤¸à¤‚à¤¬à¤°", "à¤®à¤¹à¥€à¤¨à¥‡",
        # Payee specific
        "à¤•à¤¿à¤¸à¤¨à¥‡", "à¤•à¥Œà¤¨", "payee",
        # Reason specific
        "à¤•à¤¾à¤°à¤£", "à¤ˆà¤à¤®à¤†à¤ˆ", "reason",
        # Mode specific
        "à¤®à¤¾à¤§à¥à¤¯à¤®", "mode", "à¤‘à¤¨à¤²à¤¾à¤‡à¤¨", "à¤¨à¤•à¤¦", "à¤¬à¥à¤°à¤¾à¤‚à¤š", "à¤•à¥ˆà¤¸à¥‡",
        # Confirmation specific
        "à¤¸à¤¹à¥€", "confirmation",
        # Transition specific
        "transition", "next",
        # General (lowest priority)
        "à¤­à¥à¤—à¤¤à¤¾à¤¨", "general", "acknowledgment"
    ]
    
    # Check in priority order
    for keyword in priority_keywords:
        if keyword in combined_text and keyword in FILLER_LOOKUP_TABLE:
            matching_contexts.append(keyword)
    
    return matching_contexts


def get_similarity_based_filler(transcript: str, question: Optional[str] = None) -> str:
    """
    Get filler based on similarity search with transcript and question
    
    Args:
        transcript: User's transcript from ASR
        question: Current question being asked (optional)
    
    Returns:
        Selected filler phrase
    """
    # Find matching contexts
    matching_contexts = find_matching_context(transcript, question)
    
    # If we have matching contexts, use fillers from those contexts
    candidate_fillers = []
    if matching_contexts:
        for context in matching_contexts:
            candidate_fillers.extend(FILLER_LOOKUP_TABLE[context])
        
        # Remove duplicates while preserving order
        seen = set()
        unique_candidates = []
        for filler in candidate_fillers:
            if filler not in seen:
                seen.add(filler)
                unique_candidates.append(filler)
        
        if unique_candidates:
            # Calculate similarity scores for each candidate
            combined_text = (transcript + " " + (question or "")).lower()
            filler_scores = [
                (filler, similarity_score(combined_text, filler))
                for filler in unique_candidates
            ]
            
            # Sort by similarity score (descending)
            filler_scores.sort(key=lambda x: x[1], reverse=True)
            
            # Return top 3 candidates and randomly select from them for variety
            top_candidates = [filler for filler, score in filler_scores[:3]]
            selected = random.choice(top_candidates)
            logger.info(f"ðŸŽ­ Similarity-based filler selected: '{selected}' (contexts: {matching_contexts})")
            return selected
    
    # Fallback: Use general fillers or random selection
    general_fillers = FILLER_LOOKUP_TABLE.get("general", HINDI_FILLERS)
    selected = random.choice(general_fillers)
    logger.info(f"ðŸŽ­ Fallback filler selected: '{selected}' (no matching context)")
    return selected


def should_use_filler() -> bool:
    """
    Determine if filler should be used based on probability (85% chance)
    Returns True 85% of the time
    """
    return random.random() < FILLER_PROBABILITY


def get_random_filler() -> str:
    """
    Get a random filler word/phrase from the list
    """
    return random.choice(HINDI_FILLERS)


def get_filler(
    transcript: Optional[str] = None,
    question: Optional[str] = None,
    skip_for_opening: bool = False,
    skip_for_closing: bool = False,
    use_similarity: bool = True,
) -> Optional[str]:
    """
    Get a filler word if it should be used (85% probability)
    Uses similarity search if transcript is provided, otherwise uses random selection
    
    Args:
        transcript: User's transcript from ASR (for similarity search)
        question: Current question being asked (for similarity search)
        skip_for_opening: Skip filler if this is an opening/greeting
        skip_for_closing: Skip filler if this is a closing statement
        use_similarity: Whether to use similarity-based selection (default: True)
    
    Returns filler text or None
    """
    # Skip fillers for opening and closing
    if skip_for_opening or skip_for_closing:
        logger.info(f"ðŸŽ­ Skipping filler (opening={skip_for_opening}, closing={skip_for_closing})")
        return None
    
    if should_use_filler():
        # Use similarity-based selection if transcript is provided and enabled
        if use_similarity and transcript:
            filler = get_similarity_based_filler(transcript, question)
        else:
            filler = get_random_filler()
        
        logger.info(f"ðŸŽ­ Selected filler: '{filler}'")
        return filler
    
    return None
