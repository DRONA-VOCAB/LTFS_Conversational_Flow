"""
Detailed quality assessment of Mistral responses
"""
import os
import sys
import json
import time

# Set up environment
os.environ["LLM_PROVIDER"] = "mistral"
os.environ["MISTRAL_USE_API"] = "true"
os.environ["MISTRAL_API_BASE"] = "http://192.168.30.121:5001"
os.environ["MISTRAL_API_KEY"] = "local"

# Add to path
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..', 'app'))

from llm.gemini_client import call_gemini

# Test cases with expected quality criteria
test_cases = [
    {
        "name": "Identity Confirmation with Name",
        "prompt": """You are an experienced FEMALE customer service representative from L and T Finance.

Customer said: "‡§π‡§æ‡§Å, ‡§Æ‡•à‡§Ç ‡§∞‡§æ‡§ú ‡§ï‡•Å‡§Æ‡§æ‡§∞ ‡§¨‡•ã‡§≤ ‡§∞‡§π‡§æ ‡§π‡•Ç‡§Å"

Respond naturally in Hindi, acknowledging the customer by name.

JSON format:
{
  "bot_response": "natural Hindi response",
  "extracted_data": {"identity_confirmed": "YES"},
  "next_action": "continue",
  "call_end_reason": null
}""",
        "expected_qualities": [
            "Uses customer name (‡§∞‡§æ‡§ú ‡§ï‡•Å‡§Æ‡§æ‡§∞)",
            "Polite and professional tone",
            "Female representative voice",
            "Natural Hindi"
        ]
    },
    {
        "name": "Payment Details Extraction",
        "prompt": """You are an experienced FEMALE customer service representative from L and T Finance.

Customer said: "‡§Æ‡•à‡§Ç‡§®‡•á 20 ‡§ú‡§®‡§µ‡§∞‡•Ä ‡§ï‡•ã ‡§¨‡•ç‡§∞‡§æ‡§Ç‡§ö ‡§Æ‡•á‡§Ç ‡§ú‡§æ‡§ï‡§∞ 10000 ‡§∞‡•Å‡§™‡§Ø‡•á EMI ‡§ï‡•á ‡§≤‡§ø‡§è ‡§¶‡§ø‡§è ‡§•‡•á"

Context: Customer ‡§∞‡§æ‡§ú ‡§ï‡•Å‡§Æ‡§æ‡§∞ has confirmed identity and loan.

Extract ALL payment information and provide natural acknowledgment in Hindi.

JSON format:
{
  "bot_response": "natural Hindi acknowledgment",
  "extracted_data": {
    "payment_date": "20/01/2026",
    "payment_mode": "branch",
    "payment_amount": "10000",
    "payment_reason": "emi"
  },
  "next_action": "continue",
  "call_end_reason": null
}""",
        "expected_qualities": [
            "Extracts all 4 fields correctly",
            "Date in dd/mm/yyyy format",
            "Acknowledges the payment",
            "Professional tone"
        ]
    },
    {
        "name": "Handling Unclear Response",
        "prompt": """You are an experienced FEMALE customer service representative from L and T Finance.

Customer said: "‡§π‡§Æ‡•ç‡§Æ... ‡§Æ‡•Å‡§ù‡•á ‡§Ø‡§æ‡§¶ ‡§®‡§π‡•Ä‡§Ç ‡§π‡•à"

Context: Asked about payment date.

Respond politely asking for clarification.

JSON format:
{
  "bot_response": "polite clarification request in Hindi",
  "extracted_data": {},
  "next_action": "continue",
  "call_end_reason": null
}""",
        "expected_qualities": [
            "Polite clarification request",
            "Offers help or alternatives",
            "Maintains professional tone",
            "Empathetic response"
        ]
    },
    {
        "name": "Customer Wants to Disconnect",
        "prompt": """You are an experienced FEMALE customer service representative from L and T Finance.

Customer said: "‡§Æ‡•Å‡§ù‡•á ‡§Ö‡§≠‡•Ä ‡§ú‡§æ‡§®‡§æ ‡§π‡•à, ‡§¨‡§æ‡§¶ ‡§Æ‡•á‡§Ç ‡§¨‡§æ‡§§ ‡§ï‡§∞‡§§‡•á ‡§π‡•à‡§Ç"

Context: Mid-conversation about payment details.

Respond politely and end call appropriately.

JSON format:
{
  "bot_response": "polite goodbye in Hindi",
  "extracted_data": {},
  "next_action": "end_call",
  "call_end_reason": "customer_busy"
}""",
        "expected_qualities": [
            "Polite goodbye",
            "Sets call_end_reason",
            "next_action is 'end_call'",
            "Professional closing"
        ]
    },
    {
        "name": "Multiple Details in One Response",
        "prompt": """You are an experienced FEMALE customer service representative from L and T Finance.

Customer said: "‡§Æ‡•à‡§Ç ‡§∞‡§µ‡§ø ‡§∂‡§∞‡•ç‡§Æ‡§æ ‡§π‡•Ç‡§Å ‡§î‡§∞ ‡§Æ‡•à‡§Ç‡§®‡•á 15 ‡§ú‡§®‡§µ‡§∞‡•Ä ‡§ï‡•ã ‡§ë‡§®‡§≤‡§æ‡§á‡§® 8500 ‡§∞‡•Å‡§™‡§Ø‡•á ‡§ï‡§æ ‡§™‡•á‡§Æ‡•á‡§Ç‡§ü ‡§ï‡§ø‡§Ø‡§æ ‡§•‡§æ EMI ‡§ï‡•á ‡§≤‡§ø‡§è"

Context: First response in conversation.

Extract ALL information and respond naturally.

JSON format:
{
  "bot_response": "natural Hindi response",
  "extracted_data": {
    "identity_confirmed": "YES",
    "payment_date": "15/01/2026",
    "payment_mode": "online_lan",
    "payment_amount": "8500",
    "payment_reason": "emi"
  },
  "next_action": "continue",
  "call_end_reason": null
}""",
        "expected_qualities": [
            "Extracts all 5+ fields",
            "Acknowledges identity AND payment",
            "Natural conversational flow",
            "Complete response"
        ]
    }
]

print("=" * 80)
print("üîç MISTRAL RESPONSE QUALITY ASSESSMENT")
print("=" * 80)
print(f"Server: http://192.168.30.121:5001")
print(f"Model: Mistral-7B-Instruct-v0.3 (4-bit quantized)")
print("=" * 80)
print()

quality_scores = []

for i, test in enumerate(test_cases, 1):
    print(f"\n{'=' * 80}")
    print(f"TEST {i}/5: {test['name']}")
    print(f"{'=' * 80}")
    
    start_time = time.time()
    
    try:
        result = call_gemini(test['prompt'])
        elapsed = time.time() - start_time
        
        print(f"‚è±Ô∏è  Response Time: {elapsed:.2f}s")
        print()
        
        # Check if valid JSON structure
        is_valid_json = isinstance(result, dict)
        has_bot_response = 'bot_response' in result
        
        print("üìã RESPONSE STRUCTURE:")
        print(f"  ‚úì Valid JSON: {is_valid_json}")
        print(f"  ‚úì Has bot_response: {has_bot_response}")
        if 'extracted_data' in result:
            print(f"  ‚úì Has extracted_data: True")
        if 'next_action' in result:
            print(f"  ‚úì Has next_action: {result.get('next_action')}")
        if 'call_end_reason' in result:
            print(f"  ‚úì Has call_end_reason: {result.get('call_end_reason')}")
        
        print()
        print("üí¨ BOT RESPONSE:")
        if has_bot_response:
            bot_resp = result['bot_response']
            print(f"  \"{bot_resp}\"")
            print(f"  Length: {len(bot_resp)} characters")
        else:
            print("  ‚ùå No bot_response field!")
        
        print()
        print("üìä EXTRACTED DATA:")
        if 'extracted_data' in result:
            extracted = result['extracted_data']
            if extracted:
                for key, value in extracted.items():
                    print(f"  ‚Ä¢ {key}: {value}")
            else:
                print("  (empty)")
        else:
            # Sometimes data is at root level
            print("  Data at root level:")
            for key, value in result.items():
                if key not in ['bot_response', 'next_action', 'call_end_reason']:
                    print(f"  ‚Ä¢ {key}: {value}")
        
        print()
        print("‚úÖ QUALITY CHECKLIST:")
        for quality in test['expected_qualities']:
            print(f"  ‚Ä¢ {quality}")
        
        # Calculate quality score
        score = 0
        max_score = 5
        
        # 1. Valid JSON structure
        if is_valid_json:
            score += 1
        
        # 2. Has bot_response
        if has_bot_response:
            score += 1
        
        # 3. Bot response is not empty and reasonable length
        if has_bot_response and len(result.get('bot_response', '')) > 10:
            score += 1
        
        # 4. Has extracted_data or data fields
        if 'extracted_data' in result or len(result) > 2:
            score += 1
        
        # 5. Response time is reasonable (< 5s)
        if elapsed < 5.0:
            score += 1
        
        quality_scores.append({
            'test': test['name'],
            'score': score,
            'max_score': max_score,
            'time': elapsed,
            'result': result
        })
        
        print()
        print(f"üéØ Quality Score: {score}/{max_score} ({score/max_score*100:.0f}%)")
        
    except Exception as e:
        print(f"‚ùå ERROR: {e}")
        quality_scores.append({
            'test': test['name'],
            'score': 0,
            'max_score': 5,
            'time': 0,
            'error': str(e)
        })

# Overall Summary
print(f"\n{'=' * 80}")
print("üìà OVERALL QUALITY ASSESSMENT")
print(f"{'=' * 80}")

total_score = sum(q['score'] for q in quality_scores)
max_total = sum(q['max_score'] for q in quality_scores)
avg_time = sum(q['time'] for q in quality_scores if 'time' in q) / len(quality_scores)

print(f"Overall Quality Score: {total_score}/{max_total} ({total_score/max_total*100:.1f}%)")
print(f"Average Response Time: {avg_time:.2f}s")
print()

# Quality breakdown
for q in quality_scores:
    status = "‚úÖ" if q['score'] >= q['max_score'] * 0.8 else "‚ö†Ô∏è" if q['score'] >= q['max_score'] * 0.6 else "‚ùå"
    print(f"{status} {q['test']}: {q['score']}/{q['max_score']} ({q['time']:.2f}s)")

print(f"\n{'=' * 80}")
print("üèÜ VERDICT:")
if total_score >= max_total * 0.9:
    print("üåü EXCELLENT - High quality responses with 4-bit quantization!")
elif total_score >= max_total * 0.75:
    print("üëç GOOD - Quality responses, minor improvements possible")
elif total_score >= max_total * 0.6:
    print("‚ö†Ô∏è  ACCEPTABLE - Some quality issues detected")
else:
    print("‚ùå POOR - Significant quality issues")
print(f"{'=' * 80}")

